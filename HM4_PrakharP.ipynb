{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "HM4_Prakhar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fiurGWyJGOi"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: Prakhar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhjlLQAwJGOp"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAAlroUJGOq"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DZutULHJGOq"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxjSI9uXJGOr",
        "outputId": "d30ac1b4-3a06-4175-d3f5-023e3add3359"
      },
      "source": [
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwG_YxjxJGOs"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMlfDeZlJGOs",
        "outputId": "a9442125-2f59-419c-9662-bd175b568f54"
      },
      "source": [
        "def to_one_hot(y, num_class=10):    \n",
        "    result = numpy.zeros((len(y),num_class))\n",
        "    for i,y in enumerate(y):\n",
        "        result[i,y]=1\n",
        "    return result\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g80zbQ9GJGOt"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr4vYFg9JGOt"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXc3h97hJGOu",
        "outputId": "3c805d74-1813-40fe-8b93-ee3d1b4997bf"
      },
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkEknfnhJGOu"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Nc-OKuJGOu"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-4Zv65CJGOv",
        "outputId": "3ed19dac-16f2-438b-a2c3-b32b3ab1e0eb"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.2))  \n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))  \n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,441,066\n",
            "Trainable params: 1,439,146\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr9RMv_aJGOv"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ4pSqSrJGOw",
        "outputId": "97cfceb4-b5b1-4003-a920-fc6c7a33ca8a"
      },
      "source": [
        "history = model.fit(x_tr, y_tr, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 9s 25ms/step - loss: 2.3585 - acc: 0.2492 - val_loss: 1.5436 - val_acc: 0.4483\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 1.3072 - acc: 0.5234 - val_loss: 1.6032 - val_acc: 0.4679\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 1.0782 - acc: 0.6161 - val_loss: 1.0263 - val_acc: 0.6306\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.9552 - acc: 0.6604 - val_loss: 0.8875 - val_acc: 0.6996\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 7s 24ms/step - loss: 0.8710 - acc: 0.6916 - val_loss: 0.9452 - val_acc: 0.6697\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.7905 - acc: 0.7193 - val_loss: 0.9829 - val_acc: 0.6790\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.7404 - acc: 0.7424 - val_loss: 0.7302 - val_acc: 0.7527\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.7047 - acc: 0.7563 - val_loss: 1.1621 - val_acc: 0.6426\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.6523 - acc: 0.7743 - val_loss: 0.9185 - val_acc: 0.6883\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.6338 - acc: 0.7803 - val_loss: 1.0450 - val_acc: 0.6939\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5910 - acc: 0.7946 - val_loss: 0.6481 - val_acc: 0.7839\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5737 - acc: 0.8028 - val_loss: 0.5719 - val_acc: 0.8051\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5476 - acc: 0.8110 - val_loss: 1.0448 - val_acc: 0.6810\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5390 - acc: 0.8140 - val_loss: 0.5803 - val_acc: 0.8066\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5147 - acc: 0.8244 - val_loss: 0.5585 - val_acc: 0.8124\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5043 - acc: 0.8259 - val_loss: 0.5825 - val_acc: 0.8107\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4831 - acc: 0.8324 - val_loss: 0.5848 - val_acc: 0.8091\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4694 - acc: 0.8372 - val_loss: 0.6254 - val_acc: 0.8039\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4538 - acc: 0.8431 - val_loss: 0.5594 - val_acc: 0.8097\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4614 - acc: 0.8434 - val_loss: 0.6262 - val_acc: 0.8133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JV_TwqhPJGOx",
        "outputId": "ec3f2648-353f-49ee-fd03-4b1306d33218"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoEAPU3FJGOx"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFjI4EmfJGOx"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzzeQxPYJGOy"
      },
      "source": [
        "\n",
        "learning_rate = 0.001 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaaRh8MLJGOy",
        "outputId": "6c7606f9-1be6-4c00-e7f3-5b32522da2fe"
      },
      "source": [
        "\n",
        "history = model.fit(x_train, y_train_vec, batch_size=128, epochs=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 10s 22ms/step - loss: 0.4958 - acc: 0.8325\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.4762 - acc: 0.8397\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.4594 - acc: 0.8447\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.4471 - acc: 0.8503\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.4475 - acc: 0.8506\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.4369 - acc: 0.8506\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.4176 - acc: 0.8597\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 8s 22ms/step - loss: 0.4170 - acc: 0.8590\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 8s 22ms/step - loss: 0.4085 - acc: 0.8630\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 8s 22ms/step - loss: 0.4068 - acc: 0.8627\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 8s 21ms/step - loss: 0.3967 - acc: 0.8670\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.3959 - acc: 0.8667\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.3915 - acc: 0.8667\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.3925 - acc: 0.8686\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.3828 - acc: 0.8718\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.3763 - acc: 0.8742\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.3751 - acc: 0.8745\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.3654 - acc: 0.8763\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 8s 22ms/step - loss: 0.3689 - acc: 0.8777\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 8s 22ms/step - loss: 0.3655 - acc: 0.8759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGLSqdAhJGOz"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYUd-7yyJGOz",
        "outputId": "22f7e448-0362-49fa-8dc7-183dc7a20031"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.5428 - acc: 0.8351\n",
            "loss = 0.5427564382553101\n",
            "accuracy = 0.835099995136261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrrrBHAyJGOz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}